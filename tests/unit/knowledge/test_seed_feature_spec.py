"""Tests for FeaturePlanContextBuilder.seed_feature_spec().

Verifies that feature specs are correctly seeded to Graphiti using
upsert_episode(), with proper episode body format (ADR-GBF-001)
and 3-layer graceful degradation.

Coverage Target: >=85%
Test Count: 14 tests
"""

import json
import pytest
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch

from guardkit.knowledge.feature_plan_context import (
    FeaturePlanContextBuilder,
)
from guardkit.knowledge.graphiti_client import GraphitiClient
from guardkit.integrations.graphiti.upsert_result import UpsertResult


# =========================================================================
# FIXTURES
# =========================================================================


@pytest.fixture
def project_root(tmp_path: Path) -> Path:
    """Create a temporary project root directory."""
    project_dir = tmp_path / "test_project"
    project_dir.mkdir()
    return project_dir


@pytest.fixture
def mock_graphiti_client() -> MagicMock:
    """Create a mock GraphitiClient with upsert_episode support."""
    client = MagicMock(spec=GraphitiClient)
    client.enabled = True
    client.upsert_episode = AsyncMock(
        return_value=UpsertResult.created(
            episode={"uuid": "new-uuid-123", "content": "test"},
            uuid="new-uuid-123",
        )
    )
    return client


@pytest.fixture
def sample_feature_spec() -> dict:
    """Sample feature spec dict as would be generated by /feature-plan."""
    return {
        "title": "Job-Specific Context Retrieval",
        "tasks": ["TASK-GR6-001", "TASK-GR6-002", "TASK-GR6-003"],
        "tech_stack": "python",
        "complexity": 7,
        "acceptance_criteria": [
            "Context retrieval works for all task types",
            "Budget allocation respects token limits",
        ],
        "architecture_notes": "Uses dynamic context budget allocation",
    }


# =========================================================================
# 1. SUCCESSFUL SEEDING TESTS (4 tests)
# =========================================================================


class TestSeedFeatureSpecSuccess:
    """Test successful seeding scenarios."""

    @pytest.mark.asyncio
    async def test_returns_true_on_successful_seed(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test that seed_feature_spec returns True on success."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Dynamic context budget allocation",
        )

        assert result is True

    @pytest.mark.asyncio
    async def test_calls_upsert_episode_with_correct_params(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test upsert_episode is called with correct parameters."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Dynamic context budget allocation",
        )

        mock_graphiti_client.upsert_episode.assert_called_once()
        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs

        assert call_kwargs["name"] == "feature_spec_FEAT-GR-006"
        assert call_kwargs["group_id"] == "feature_specs"
        assert call_kwargs["entity_id"] == "FEAT-GR-006"
        assert call_kwargs["source"] == "feature_plan"
        assert call_kwargs["entity_type"] == "feature_spec"

    @pytest.mark.asyncio
    async def test_episode_body_contains_domain_data_only(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test episode body follows ADR-GBF-001 (domain data only)."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Dynamic context budget allocation",
        )

        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs
        episode_body = json.loads(call_kwargs["episode_body"])

        # Domain data fields MUST be present
        assert episode_body["id"] == "FEAT-GR-006"
        assert episode_body["title"] == "Job-Specific Context Retrieval"
        assert episode_body["description"] == "Dynamic context budget allocation"
        assert episode_body["tasks"] == ["TASK-GR6-001", "TASK-GR6-002", "TASK-GR6-003"]
        assert episode_body["tech_stack"] == "python"
        assert episode_body["complexity"] == 7
        assert episode_body["acceptance_criteria"] == [
            "Context retrieval works for all task types",
            "Budget allocation respects token limits",
        ]
        assert episode_body["architecture_notes"] == "Uses dynamic context budget allocation"
        assert episode_body["status"] == "planned"

        # Metadata fields MUST NOT be present (ADR-GBF-001)
        assert "_metadata" not in episode_body
        assert "entity_type" not in episode_body
        assert "source" not in episode_body
        assert "created_at" not in episode_body

    @pytest.mark.asyncio
    async def test_uses_description_as_title_fallback(
        self, project_root, mock_graphiti_client
    ):
        """Test that description is used as title when spec has no title."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        await builder.seed_feature_spec(
            feature_id="FEAT-GR-007",
            feature_spec={},  # No title in spec
            description="My feature description",
        )

        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs
        episode_body = json.loads(call_kwargs["episode_body"])

        assert episode_body["title"] == "My feature description"


# =========================================================================
# 2. GRACEFUL DEGRADATION TESTS (4 tests)
# =========================================================================


class TestSeedFeatureSpecGracefulDegradation:
    """Test 3-layer graceful degradation pattern."""

    @pytest.mark.asyncio
    async def test_returns_false_when_client_is_none(
        self, project_root, sample_feature_spec
    ):
        """Layer 1: Returns False when graphiti_client is None."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = None

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        assert result is False

    @pytest.mark.asyncio
    async def test_returns_false_when_client_disabled(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Layer 2: Returns False when graphiti_client.enabled is False."""
        mock_graphiti_client.enabled = False

        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        assert result is False
        mock_graphiti_client.upsert_episode.assert_not_called()

    @pytest.mark.asyncio
    async def test_returns_false_on_upsert_exception(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Layer 3: Returns False when upsert_episode raises exception."""
        mock_graphiti_client.upsert_episode = AsyncMock(
            side_effect=Exception("Connection refused")
        )

        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        assert result is False

    @pytest.mark.asyncio
    async def test_returns_false_when_upsert_returns_none(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test returns False when upsert_episode returns None."""
        mock_graphiti_client.upsert_episode = AsyncMock(return_value=None)

        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        assert result is False


# =========================================================================
# 3. UPSERT BEHAVIOR TESTS (3 tests)
# =========================================================================


class TestSeedFeatureSpecUpsertBehavior:
    """Test upsert deduplication behavior."""

    @pytest.mark.asyncio
    async def test_returns_true_on_update(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test returns True when upsert updates existing episode."""
        mock_graphiti_client.upsert_episode = AsyncMock(
            return_value=UpsertResult.updated(
                episode={"uuid": "updated-uuid", "content": "updated"},
                uuid="updated-uuid",
                previous_uuid="old-uuid",
            )
        )

        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        assert result is True

    @pytest.mark.asyncio
    async def test_returns_true_on_skip(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test returns True when upsert skips (content unchanged)."""
        mock_graphiti_client.upsert_episode = AsyncMock(
            return_value=UpsertResult.skipped(
                episode={"uuid": "existing-uuid", "content": "same"},
                uuid="existing-uuid",
            )
        )

        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-GR-006",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        assert result is True

    @pytest.mark.asyncio
    async def test_entity_id_matches_feature_id(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test entity_id is set to feature_id for deduplication."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        await builder.seed_feature_spec(
            feature_id="FEAT-CUSTOM-123",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs
        assert call_kwargs["entity_id"] == "FEAT-CUSTOM-123"


# =========================================================================
# 4. EDGE CASE TESTS (3 tests)
# =========================================================================


class TestSeedFeatureSpecEdgeCases:
    """Test edge cases and missing data handling."""

    @pytest.mark.asyncio
    async def test_handles_empty_feature_spec(
        self, project_root, mock_graphiti_client
    ):
        """Test seeding with empty feature_spec dict uses defaults."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        result = await builder.seed_feature_spec(
            feature_id="FEAT-EMPTY-001",
            feature_spec={},
            description="Minimal feature",
        )

        assert result is True

        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs
        episode_body = json.loads(call_kwargs["episode_body"])

        # Default values should be used
        assert episode_body["title"] == "Minimal feature"  # Falls back to description
        assert episode_body["tasks"] == []
        assert episode_body["tech_stack"] == "python"
        assert episode_body["complexity"] is None
        assert episode_body["acceptance_criteria"] == []
        assert episode_body["architecture_notes"] == ""

    @pytest.mark.asyncio
    async def test_handles_spec_with_extra_fields(
        self, project_root, mock_graphiti_client
    ):
        """Test that extra fields in feature_spec are ignored in episode body."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        spec_with_extras = {
            "title": "My Feature",
            "unknown_field": "should be ignored",
            "internal_state": {"data": 123},
        }

        result = await builder.seed_feature_spec(
            feature_id="FEAT-EXTRA-001",
            feature_spec=spec_with_extras,
            description="Test",
        )

        assert result is True

        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs
        episode_body = json.loads(call_kwargs["episode_body"])

        # Extra fields should NOT appear in episode body
        assert "unknown_field" not in episode_body
        assert "internal_state" not in episode_body

    @pytest.mark.asyncio
    async def test_episode_body_is_valid_json_string(
        self, project_root, mock_graphiti_client, sample_feature_spec
    ):
        """Test that episode_body is a valid JSON string (not dict)."""
        builder = FeaturePlanContextBuilder(project_root=project_root)
        builder.graphiti_client = mock_graphiti_client

        await builder.seed_feature_spec(
            feature_id="FEAT-JSON-001",
            feature_spec=sample_feature_spec,
            description="Test",
        )

        call_kwargs = mock_graphiti_client.upsert_episode.call_args.kwargs
        episode_body_raw = call_kwargs["episode_body"]

        # Must be a string, not a dict
        assert isinstance(episode_body_raw, str)
        # Must be valid JSON
        parsed = json.loads(episode_body_raw)
        assert isinstance(parsed, dict)
